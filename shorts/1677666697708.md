Here's a performance-focused refactoring pattern I've applied a few times to great effect. In my head, I call it a "promise pipeline" but there's nothing super special about it – you could also just call it "writing fast concurrent code".

Let's say I've been tasked with speeding up “image jobs” while working at some company that mails framed photographs to customers every month. I'm working with code that already exists and is running in production so I don't have time to rewrite it from scratch or ship new infrastructure. The goal is to just make the code faster.

Since I [profiled before optimizing](http://wiki.c2.com/?ProfileBeforeOptimizing), I've narrowed the issue down to a slow function that glues together calls to external services. This function receives a list of image links and needs to:

- Download them
- Upscale them using AI
- Make a third-party API to mail the customer each image

Here's what we're starting with:

```tsx
async function handleImages(user: User, imageURLs: string[]) {
  // Download images
  const images: Blob[] = [];
  for (const imageURL of imageURLs) {
    images.push(await (await fetch(imageURL)).blob());
  }

  // Upscale them
  const upscaledImages: Blob[] = [];
  for (const image of images) {
    upscaledImages.push(await upscale(image));
  }

  // Mail them to the user
  for (const upscaleImage of upscaledImages) {
    await user.mail(upscaleImage);
  }
}
```

Maybe you've spotted the first problem. This function does one thing at a time! It uploads images one-by-one, and then upscales them one-by-one, and then finally mails them one-by-one. For 50 images, it takes ~8.5 seconds to complete.

Let's add some concurrency — with limits so that we can respect our contracts with external services. For same-process concurrency limits in JavaScript, I like the semaphore pattern (e.g. [deno-semaphore](https://deno.land/x/semaphore@v1.1.2), [await-semaphore](https://www.npmjs.com/package/await-semaphore)).

```tsx
async function handleImages2(user: User, imageURLs: string[]) {
  // Through trial and error, we found that other services
  // can handle up to this amount of load
  const downloadSemaphore = new Semaphore(5);
  const upscaleSemaphore = new Semaphore(5);
  const mailSemaphore = new Semaphore(5);

  // Download images (5 at a time)
  const images = imageURLs.map(async (imageURL) => {
    await downloadSemaphore.acquire();
    const image = (await fetch(imageURL)).blob();
    downloadSemaphore.release();
    return image;
  });
  await Promise.all(images);

  // Upscale them (5 at a time)
  const upscaledImages = images.map(async (image) => {
    await upscaleSemaphore.acquire();
    const blob = await upscale(image);
    upscaleSemaphore.release();
    return blob;
  });
  await Promise.all(upscaledImages);

  // Mail them to the user (5 at a time)
  const mailTasks = upscaledImages.map(async (upscaledImage) => {
    await mailSemaphore.acquire();
    await user.mail(upscaledImage);
    mailSemaphore.release();
  });
  await Promise.all(mailTasks);
}
```

We had to make the function longer. But it's faster. It takes ~1.2s — an improvement of 7x.

Let's say that this isn't enough. Speeding up image jobs is priority zero on the roadmap.

We can take our performance refactoring one step further if we think about how data flows through our function. As it's currently written, there are no guarantees around when images should be mailed to users – only that they should all be mailed by the time the function returns.

Here's the key fact: an image doesn't depend on the progress of another image.

Instead of designing our function with shared steps that block the progress of all images:

- download images → upscale images → mail images

We can instead think about the flow of each individual image:

- download image A → upscale image A → mail image A
- download image B → upscale image B → mail image B
- download image C → upscale image C → mail image C

If we run these flows concurrently, while still respecting contracts with external services, we will achieve optimal concurrency.

We end up needing less code too.

```tsx
async function handleImages3(user: User, imageURLs: string[]) {
  const downloadSemaphore = new Semaphore(5);
  const upscaleSemaphore = new Semaphore(5);
  const mailSemaphore = new Semaphore(5);

  // Images don't depend on each other!
  // They can flow between steps independently
  const pipeline = imageURLs.map(async (imageURL) => {
    await downloadSemaphore.acquire();
    const image = (await fetch(imageURL)).blob();
    downloadSemaphore.release();

    await upscaleSemaphore.acquire();
    const upscaledImage = await upscale(image);
    upscaleSemaphore.release();

    await mailSemaphore.acquire();
    await user.mail(upscaledImage);
    mailSemaphore.release();
  });

  await Promise.all(pipeline);
}
```

Instead of taking as long as the sum of: the slowest download, the slowest upscale, and the slowest mail call. The function will now take as long as: the image with the slowest combination of calls.

This final version of the function takes ~700ms — a speed-up of 1.7x.

If you're wondering how I arrived at these numbers, I wrote a test script to measure each version with 50 image URLs, and mocked external calls so they would take `Math.random() * 100` milliseconds.

In the real world, calls to other services don't take an evenly distributed amount of time. Calls have spikes and high P99 latencies – so the impact of going from version two to three is actually much higher!

(In theory, there are rare circumstances where version two and version three can take the same amount of time for some inputs but in practice version three will always be faster).